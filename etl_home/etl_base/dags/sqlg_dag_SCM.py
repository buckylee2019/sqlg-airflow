
# -*- coding: utf-8 -*-
# Author        : Jesse Wei
# LastUpdate    : 2020/10/04
# Impact        : Jobs generated by SQLG
# Message       : Humanity towards others, we live by sharing. Fear can hold you prisoner, only hope can set you free.

# from __future__ import print_function
import logging
import re
import airflow
import pendulum
from datetime import datetime, timedelta
from airflow.operators.sensors import ExternalTaskSensor
from airflow.operators.python_operator import PythonOperator
from airflow.operators.bash_operator import BashOperator
from airflow.contrib.sensors.file_sensor import FileSensor
from airflow import models
from airflow.models import Variable, DagModel, DagBag
from airflow.operators.python_operator import BranchPythonOperator
from airflow.operators.dummy_operator import DummyOperator


# For ODP platform
# from acme.operators.sqlg_oracle import OracleOperatorWithTemplatedParams
# from airflow.operators.oracle_operator import OracleOperator

from acme.operators.sqlg_mssql import MsSqlOperatorWithTemplatedParams
from airflow.operators.mssql_operator import MsSqlOperator

# DB_NAME = 'DWH' # for future xDB operator

proj_start_date = pendulum.datetime(2021, 1, 1,  tzinfo="Etc/GMT-8")
tmpl_search_path = Variable.get("sql_path")
data_stage_imp_ptn = '_ODS_'
data_stage = []

# list for standard internval order sequence
std_interval = {
    '@once' 		:1,
    '@hourly' 		:2,
    '0 5 * * *'		:3,
    '0 5 * * 0'		:4,
    '0 5 1 * *'		:5,
    '0 5 1 */3 *'	:6,
    '0 5 1 1 *'		:7,
}

# function to sync execution for diff frequency
def sqlg_exec_date_fn(dt, context):
    var_date = Variable.get("sqlg_execution_date")
    ti = context['ti']
    dag = context['dag']
    ti_exec_date = context['execution_date'] 
    schedule_interval = dag.schedule_interval
    
    # if wait INIT and standard freq then set as default {{ ds }} # set in planner
    # else use dag own execution date
    if ti.task.external_dag_id == 'D_STG_INIT' and schedule_interval[0] == '@':
        exec_date = pendulum.parse(var_date)
    else:        
        exec_date = ti_exec_date

    print("sqlg_exec_date_fn::DEBUG:external_dag_id, exec_date:", ti.task.external_dag_id, exec_date)
    return exec_date




args = {
    "owner": "SPA010038",
    'start_date': proj_start_date,
    'provide_context': True
}	
# XSLT:loop: declaration: END}


# XSLT:loop: JOB_FLOW_NAME: START{
job_flow_name = "D_ODS_SCM"
data_stage = job_flow_name.split('_')
tags = data_stage
D_ODS_SCM = airflow.DAG(
    "D_ODS_SCM",
    tags=tags, 
    schedule_interval="0 5 * * *",
    dagrun_timeout=timedelta(minutes=60*4),
    template_searchpath=tmpl_search_path,
    default_args=args,
    # start_date=proj_start_date,    
    max_active_runs=1
	)
job_flow_name = "D_DM_SCM"
data_stage = job_flow_name.split('_')
tags = data_stage
D_DM_SCM = airflow.DAG(
    "D_DM_SCM",
    tags=tags, 
    schedule_interval="0 5 * * *",
    dagrun_timeout=timedelta(minutes=60*4),
    template_searchpath=tmpl_search_path,
    default_args=args,
    # start_date=proj_start_date,    
    max_active_runs=1
	)
job_flow_name = "D_INT_SCM"
data_stage = job_flow_name.split('_')
tags = data_stage
D_INT_SCM = airflow.DAG(
    "D_INT_SCM",
    tags=tags, 
    schedule_interval="0 5 * * *",
    dagrun_timeout=timedelta(minutes=60*4),
    template_searchpath=tmpl_search_path,
    default_args=args,
    # start_date=proj_start_date,    
    max_active_runs=1
	)

# XSLT:loop: JOB_FLOW_NAME: END}


# JOB_TYPE=ODS-MAIN
my_taskid = "PNL_Revenue_Cost_A"
PNL_Revenue_Cost_A = MsSqlOperatorWithTemplatedParams(
    auto_commit=True,
    task_id=my_taskid,
    pool = "sql_pool",
    dag=D_ODS_SCM,

    # parameters=({":END_DT_CHAR":"{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}"}),    
    timeout=60*60*3,
    sql= "EXECUTE SQLEXT." + my_taskid + "_SP "+  
        "{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}" + 
        ";"
    )

# JOB_TYPE=ODS-MAIN
my_taskid = "NRE_Summary"
NRE_Summary = MsSqlOperatorWithTemplatedParams(
    auto_commit=True,
    task_id=my_taskid,
    pool = "sql_pool",
    dag=D_ODS_SCM,

    # parameters=({":END_DT_CHAR":"{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}"}),    
    timeout=60*60*3,
    sql= "EXECUTE SQLEXT." + my_taskid + "_SP "+  
        "{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}" + 
        ";"
    )

# JOB_TYPE=ODS-MAIN
my_taskid = "Daily_Revenue_F"
Daily_Revenue_F = MsSqlOperatorWithTemplatedParams(
    auto_commit=True,
    task_id=my_taskid,
    pool = "sql_pool",
    dag=D_ODS_SCM,

    # parameters=({":END_DT_CHAR":"{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}"}),    
    timeout=60*60*3,
    sql= "EXECUTE SQLEXT." + my_taskid + "_SP "+  
        "{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}" + 
        ";"
    )

# JOB_TYPE=ODS-MAIN
my_taskid = "RFQ_Master"
RFQ_Master = MsSqlOperatorWithTemplatedParams(
    auto_commit=True,
    task_id=my_taskid,
    pool = "sql_pool",
    dag=D_ODS_SCM,

    # parameters=({":END_DT_CHAR":"{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}"}),    
    timeout=60*60*3,
    sql= "EXECUTE SQLEXT." + my_taskid + "_SP "+  
        "{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}" + 
        ";"
    )

# JOB_TYPE=ODS-MAIN
my_taskid = "Inventory_A"
Inventory_A = MsSqlOperatorWithTemplatedParams(
    auto_commit=True,
    task_id=my_taskid,
    pool = "sql_pool",
    dag=D_ODS_SCM,

    # parameters=({":END_DT_CHAR":"{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}"}),    
    timeout=60*60*3,
    sql= "EXECUTE SQLEXT." + my_taskid + "_SP "+  
        "{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}" + 
        ";"
    )

# JOB_TYPE=ODS-MAIN
my_taskid = "DOI_Actual"
DOI_Actual = MsSqlOperatorWithTemplatedParams(
    auto_commit=True,
    task_id=my_taskid,
    pool = "sql_pool",
    dag=D_ODS_SCM,

    # parameters=({":END_DT_CHAR":"{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}"}),    
    timeout=60*60*3,
    sql= "EXECUTE SQLEXT." + my_taskid + "_SP "+  
        "{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}" + 
        ";"
    )

# JOB_TYPE=ODS-MAIN
my_taskid = "DM_PNL_Revenue_Cost_A"
DM_PNL_Revenue_Cost_A = MsSqlOperatorWithTemplatedParams(
    auto_commit=True,
    task_id=my_taskid,
    pool = "sql_pool",
    dag=D_DM_SCM,

    # parameters=({":END_DT_CHAR":"{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}"}),    
    timeout=60*60*3,
    sql= "EXECUTE SQLEXT." + my_taskid + "_SP "+  
        "{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}" + 
        ";"
    )

# JOB_TYPE=ODS-MAIN
my_taskid = "DM_NRE_Summary"
DM_NRE_Summary = MsSqlOperatorWithTemplatedParams(
    auto_commit=True,
    task_id=my_taskid,
    pool = "sql_pool",
    dag=D_DM_SCM,

    # parameters=({":END_DT_CHAR":"{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}"}),    
    timeout=60*60*3,
    sql= "EXECUTE SQLEXT." + my_taskid + "_SP "+  
        "{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}" + 
        ";"
    )

# JOB_TYPE=ODS-MAIN
my_taskid = "DM_Daily_Revenue_F"
DM_Daily_Revenue_F = MsSqlOperatorWithTemplatedParams(
    auto_commit=True,
    task_id=my_taskid,
    pool = "sql_pool",
    dag=D_DM_SCM,

    # parameters=({":END_DT_CHAR":"{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}"}),    
    timeout=60*60*3,
    sql= "EXECUTE SQLEXT." + my_taskid + "_SP "+  
        "{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}" + 
        ";"
    )

# JOB_TYPE=ODS-MAIN
my_taskid = "DM_RFQ_Master"
DM_RFQ_Master = MsSqlOperatorWithTemplatedParams(
    auto_commit=True,
    task_id=my_taskid,
    pool = "sql_pool",
    dag=D_DM_SCM,

    # parameters=({":END_DT_CHAR":"{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}"}),    
    timeout=60*60*3,
    sql= "EXECUTE SQLEXT." + my_taskid + "_SP "+  
        "{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}" + 
        ";"
    )

# JOB_TYPE=ODS-MAIN
my_taskid = "DM_Inventory_A"
DM_Inventory_A = MsSqlOperatorWithTemplatedParams(
    auto_commit=True,
    task_id=my_taskid,
    pool = "sql_pool",
    dag=D_DM_SCM,

    # parameters=({":END_DT_CHAR":"{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}"}),    
    timeout=60*60*3,
    sql= "EXECUTE SQLEXT." + my_taskid + "_SP "+  
        "{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}" + 
        ";"
    )

# JOB_TYPE=ODS-MAIN
my_taskid = "DM_DOI_Actual"
DM_DOI_Actual = MsSqlOperatorWithTemplatedParams(
    auto_commit=True,
    task_id=my_taskid,
    pool = "sql_pool",
    dag=D_DM_SCM,

    # parameters=({":END_DT_CHAR":"{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}"}),    
    timeout=60*60*3,
    sql= "EXECUTE SQLEXT." + my_taskid + "_SP "+  
        "{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}" + 
        ";"
    )

# JOB_TYPE=ODS-MAIN
my_taskid = "INT_PNL_Revenue_Cost_A"
INT_PNL_Revenue_Cost_A = MsSqlOperatorWithTemplatedParams(
    auto_commit=True,
    task_id=my_taskid,
    pool = "sql_pool",
    dag=D_INT_SCM,

    # parameters=({":END_DT_CHAR":"{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}"}),    
    timeout=60*60*3,
    sql= "EXECUTE SQLEXT." + my_taskid + "_SP "+  
        "{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}" + 
        ";"
    )

# JOB_TYPE=ODS-MAIN
my_taskid = "INT_NRE_Summary"
INT_NRE_Summary = MsSqlOperatorWithTemplatedParams(
    auto_commit=True,
    task_id=my_taskid,
    pool = "sql_pool",
    dag=D_INT_SCM,

    # parameters=({":END_DT_CHAR":"{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}"}),    
    timeout=60*60*3,
    sql= "EXECUTE SQLEXT." + my_taskid + "_SP "+  
        "{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}" + 
        ";"
    )

# JOB_TYPE=ODS-MAIN
my_taskid = "INT_Daily_Revenue_F"
INT_Daily_Revenue_F = MsSqlOperatorWithTemplatedParams(
    auto_commit=True,
    task_id=my_taskid,
    pool = "sql_pool",
    dag=D_INT_SCM,

    # parameters=({":END_DT_CHAR":"{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}"}),    
    timeout=60*60*3,
    sql= "EXECUTE SQLEXT." + my_taskid + "_SP "+  
        "{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}" + 
        ";"
    )

# JOB_TYPE=ODS-MAIN
my_taskid = "INT_RFQ_Master"
INT_RFQ_Master = MsSqlOperatorWithTemplatedParams(
    auto_commit=True,
    task_id=my_taskid,
    pool = "sql_pool",
    dag=D_INT_SCM,

    # parameters=({":END_DT_CHAR":"{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}"}),    
    timeout=60*60*3,
    sql= "EXECUTE SQLEXT." + my_taskid + "_SP "+  
        "{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}" + 
        ";"
    )

# JOB_TYPE=ODS-MAIN
my_taskid = "INT_Inventory_A"
INT_Inventory_A = MsSqlOperatorWithTemplatedParams(
    auto_commit=True,
    task_id=my_taskid,
    pool = "sql_pool",
    dag=D_INT_SCM,

    # parameters=({":END_DT_CHAR":"{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}"}),    
    timeout=60*60*3,
    sql= "EXECUTE SQLEXT." + my_taskid + "_SP "+  
        "{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}" + 
        ";"
    )

# JOB_TYPE=ODS-MAIN
my_taskid = "INT_DOI_Actual"
INT_DOI_Actual = MsSqlOperatorWithTemplatedParams(
    auto_commit=True,
    task_id=my_taskid,
    pool = "sql_pool",
    dag=D_INT_SCM,

    # parameters=({":END_DT_CHAR":"{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}"}),    
    timeout=60*60*3,
    sql= "EXECUTE SQLEXT." + my_taskid + "_SP "+  
        "{{ (execution_date.astimezone('Asia/Taipei')).strftime('%Y%m%d') }}" + 
        ";"
    )


ExternalTaskSensor.ui_color = 'white'
ExternalTaskSensor.ui_fgcolor = 'blue'

# tmpl_search_path = Variable.get("sql_path")
	

# 	XSLT:loop: JOB_FLOW_NAME-and-PRE_JOB: External:START{{

def branch_D_ODS_SCMxD_STG_INIT__SYS_STS_STG(**context):
    mydag = context["dag"]
    dagbag = DagBag()
    upstream = dagbag.get_dag("D_STG_INIT")
			
    # print("branch::DEBUG:upstream.latest_execution_date:", upstream.latest_execution_date)
    # print("branch::DEBUG:mydag.execution_date:", context['execution_date'])
    up_sch_interval = std_interval.get(upstream.schedule_interval)
    my_sch_interval = std_interval.get(mydag.schedule_interval)

    if up_sch_interval is None or my_sch_interval is None:
        if (up_sch_interval is None and my_sch_interval is None) and (upstream.schedule_interval == mydag.schedule_interval):
            return ["proxy_D_ODS_SCMxD_STG_INIT__SYS_STS_STG","D_ODS_SCMxD_STG_INIT__SYS_STS_STG"]
    elif std_interval[upstream.schedule_interval] >= std_interval[mydag.schedule_interval]:
        if upstream.latest_execution_date == context["execution_date"]:
            return ["proxy_D_ODS_SCMxD_STG_INIT__SYS_STS_STG","D_ODS_SCMxD_STG_INIT__SYS_STS_STG"]
    return ["proxy_D_ODS_SCMxD_STG_INIT__SYS_STS_STG"]


my_taskid = "BRANCH_D_ODS_SCMxD_STG_INIT__SYS_STS_STG"
BRANCH_D_ODS_SCMxD_STG_INIT__SYS_STS_STG= BranchPythonOperator(
    task_id=my_taskid,
    python_callable=branch_D_ODS_SCMxD_STG_INIT__SYS_STS_STG,
    dag=D_ODS_SCM,
    provide_context=True,
)


my_taskid = "proxy_D_ODS_SCMxD_STG_INIT__SYS_STS_STG"
proxy_D_ODS_SCMxD_STG_INIT__SYS_STS_STG= DummyOperator(
    task_id=my_taskid,
    trigger_rule="none_failed_or_skipped",
    dag=D_ODS_SCM,
)


#   Cross dag sensor
			
my_taskid = "D_ODS_SCMxD_STG_INIT__SYS_STS_STG"
D_ODS_SCMxD_STG_INIT__SYS_STS_STG= ExternalTaskSensor(
    pool = "sensor_pool",
    task_id=my_taskid,
    external_dag_id="D_STG_INIT",
    external_task_id="SYS_STS_STG",
    mode="reschedule",
    dag=D_ODS_SCM,
    check_existence=True,
    timeout=60*60*1,
    retries=5,
    retry_delay=timedelta(minutes=3),
    execution_date_fn=sqlg_exec_date_fn
)


BRANCH_D_ODS_SCMxD_STG_INIT__SYS_STS_STG.set_downstream(proxy_D_ODS_SCMxD_STG_INIT__SYS_STS_STG)

BRANCH_D_ODS_SCMxD_STG_INIT__SYS_STS_STG.set_downstream(D_ODS_SCMxD_STG_INIT__SYS_STS_STG)

D_ODS_SCMxD_STG_INIT__SYS_STS_STG.set_downstream(proxy_D_ODS_SCMxD_STG_INIT__SYS_STS_STG)

def branch_D_DM_SCMxD_INT_SCM__INT_PNL_Revenue_Cost_A(**context):
    mydag = context["dag"]
    dagbag = DagBag()
    upstream = dagbag.get_dag("D_INT_SCM")
			
    # print("branch::DEBUG:upstream.latest_execution_date:", upstream.latest_execution_date)
    # print("branch::DEBUG:mydag.execution_date:", context['execution_date'])
    up_sch_interval = std_interval.get(upstream.schedule_interval)
    my_sch_interval = std_interval.get(mydag.schedule_interval)

    if up_sch_interval is None or my_sch_interval is None:
        if (up_sch_interval is None and my_sch_interval is None) and (upstream.schedule_interval == mydag.schedule_interval):
            return ["proxy_D_DM_SCMxD_INT_SCM__INT_PNL_Revenue_Cost_A","D_DM_SCMxD_INT_SCM__INT_PNL_Revenue_Cost_A"]
    elif std_interval[upstream.schedule_interval] >= std_interval[mydag.schedule_interval]:
        if upstream.latest_execution_date == context["execution_date"]:
            return ["proxy_D_DM_SCMxD_INT_SCM__INT_PNL_Revenue_Cost_A","D_DM_SCMxD_INT_SCM__INT_PNL_Revenue_Cost_A"]
    return ["proxy_D_DM_SCMxD_INT_SCM__INT_PNL_Revenue_Cost_A"]


my_taskid = "BRANCH_D_DM_SCMxD_INT_SCM__INT_PNL_Revenue_Cost_A"
BRANCH_D_DM_SCMxD_INT_SCM__INT_PNL_Revenue_Cost_A= BranchPythonOperator(
    task_id=my_taskid,
    python_callable=branch_D_DM_SCMxD_INT_SCM__INT_PNL_Revenue_Cost_A,
    dag=D_DM_SCM,
    provide_context=True,
)


my_taskid = "proxy_D_DM_SCMxD_INT_SCM__INT_PNL_Revenue_Cost_A"
proxy_D_DM_SCMxD_INT_SCM__INT_PNL_Revenue_Cost_A= DummyOperator(
    task_id=my_taskid,
    trigger_rule="none_failed_or_skipped",
    dag=D_DM_SCM,
)


#   Cross dag sensor
			
my_taskid = "D_DM_SCMxD_INT_SCM__INT_PNL_Revenue_Cost_A"
D_DM_SCMxD_INT_SCM__INT_PNL_Revenue_Cost_A= ExternalTaskSensor(
    pool = "sensor_pool",
    task_id=my_taskid,
    external_dag_id="D_INT_SCM",
    external_task_id="INT_PNL_Revenue_Cost_A",
    mode="reschedule",
    dag=D_DM_SCM,
    check_existence=True,
    timeout=60*60*1,
    retries=5,
    retry_delay=timedelta(minutes=3),
    execution_date_fn=sqlg_exec_date_fn
)


BRANCH_D_DM_SCMxD_INT_SCM__INT_PNL_Revenue_Cost_A.set_downstream(proxy_D_DM_SCMxD_INT_SCM__INT_PNL_Revenue_Cost_A)

BRANCH_D_DM_SCMxD_INT_SCM__INT_PNL_Revenue_Cost_A.set_downstream(D_DM_SCMxD_INT_SCM__INT_PNL_Revenue_Cost_A)

D_DM_SCMxD_INT_SCM__INT_PNL_Revenue_Cost_A.set_downstream(proxy_D_DM_SCMxD_INT_SCM__INT_PNL_Revenue_Cost_A)

def branch_D_DM_SCMxD_INT_SCM__INT_NRE_Summary(**context):
    mydag = context["dag"]
    dagbag = DagBag()
    upstream = dagbag.get_dag("D_INT_SCM")
			
    # print("branch::DEBUG:upstream.latest_execution_date:", upstream.latest_execution_date)
    # print("branch::DEBUG:mydag.execution_date:", context['execution_date'])
    up_sch_interval = std_interval.get(upstream.schedule_interval)
    my_sch_interval = std_interval.get(mydag.schedule_interval)

    if up_sch_interval is None or my_sch_interval is None:
        if (up_sch_interval is None and my_sch_interval is None) and (upstream.schedule_interval == mydag.schedule_interval):
            return ["proxy_D_DM_SCMxD_INT_SCM__INT_NRE_Summary","D_DM_SCMxD_INT_SCM__INT_NRE_Summary"]
    elif std_interval[upstream.schedule_interval] >= std_interval[mydag.schedule_interval]:
        if upstream.latest_execution_date == context["execution_date"]:
            return ["proxy_D_DM_SCMxD_INT_SCM__INT_NRE_Summary","D_DM_SCMxD_INT_SCM__INT_NRE_Summary"]
    return ["proxy_D_DM_SCMxD_INT_SCM__INT_NRE_Summary"]


my_taskid = "BRANCH_D_DM_SCMxD_INT_SCM__INT_NRE_Summary"
BRANCH_D_DM_SCMxD_INT_SCM__INT_NRE_Summary= BranchPythonOperator(
    task_id=my_taskid,
    python_callable=branch_D_DM_SCMxD_INT_SCM__INT_NRE_Summary,
    dag=D_DM_SCM,
    provide_context=True,
)


my_taskid = "proxy_D_DM_SCMxD_INT_SCM__INT_NRE_Summary"
proxy_D_DM_SCMxD_INT_SCM__INT_NRE_Summary= DummyOperator(
    task_id=my_taskid,
    trigger_rule="none_failed_or_skipped",
    dag=D_DM_SCM,
)


#   Cross dag sensor
			
my_taskid = "D_DM_SCMxD_INT_SCM__INT_NRE_Summary"
D_DM_SCMxD_INT_SCM__INT_NRE_Summary= ExternalTaskSensor(
    pool = "sensor_pool",
    task_id=my_taskid,
    external_dag_id="D_INT_SCM",
    external_task_id="INT_NRE_Summary",
    mode="reschedule",
    dag=D_DM_SCM,
    check_existence=True,
    timeout=60*60*1,
    retries=5,
    retry_delay=timedelta(minutes=3),
    execution_date_fn=sqlg_exec_date_fn
)


BRANCH_D_DM_SCMxD_INT_SCM__INT_NRE_Summary.set_downstream(proxy_D_DM_SCMxD_INT_SCM__INT_NRE_Summary)

BRANCH_D_DM_SCMxD_INT_SCM__INT_NRE_Summary.set_downstream(D_DM_SCMxD_INT_SCM__INT_NRE_Summary)

D_DM_SCMxD_INT_SCM__INT_NRE_Summary.set_downstream(proxy_D_DM_SCMxD_INT_SCM__INT_NRE_Summary)

def branch_D_DM_SCMxD_INT_SCM__INT_Daily_Revenue_F(**context):
    mydag = context["dag"]
    dagbag = DagBag()
    upstream = dagbag.get_dag("D_INT_SCM")
			
    # print("branch::DEBUG:upstream.latest_execution_date:", upstream.latest_execution_date)
    # print("branch::DEBUG:mydag.execution_date:", context['execution_date'])
    up_sch_interval = std_interval.get(upstream.schedule_interval)
    my_sch_interval = std_interval.get(mydag.schedule_interval)

    if up_sch_interval is None or my_sch_interval is None:
        if (up_sch_interval is None and my_sch_interval is None) and (upstream.schedule_interval == mydag.schedule_interval):
            return ["proxy_D_DM_SCMxD_INT_SCM__INT_Daily_Revenue_F","D_DM_SCMxD_INT_SCM__INT_Daily_Revenue_F"]
    elif std_interval[upstream.schedule_interval] >= std_interval[mydag.schedule_interval]:
        if upstream.latest_execution_date == context["execution_date"]:
            return ["proxy_D_DM_SCMxD_INT_SCM__INT_Daily_Revenue_F","D_DM_SCMxD_INT_SCM__INT_Daily_Revenue_F"]
    return ["proxy_D_DM_SCMxD_INT_SCM__INT_Daily_Revenue_F"]


my_taskid = "BRANCH_D_DM_SCMxD_INT_SCM__INT_Daily_Revenue_F"
BRANCH_D_DM_SCMxD_INT_SCM__INT_Daily_Revenue_F= BranchPythonOperator(
    task_id=my_taskid,
    python_callable=branch_D_DM_SCMxD_INT_SCM__INT_Daily_Revenue_F,
    dag=D_DM_SCM,
    provide_context=True,
)


my_taskid = "proxy_D_DM_SCMxD_INT_SCM__INT_Daily_Revenue_F"
proxy_D_DM_SCMxD_INT_SCM__INT_Daily_Revenue_F= DummyOperator(
    task_id=my_taskid,
    trigger_rule="none_failed_or_skipped",
    dag=D_DM_SCM,
)


#   Cross dag sensor
			
my_taskid = "D_DM_SCMxD_INT_SCM__INT_Daily_Revenue_F"
D_DM_SCMxD_INT_SCM__INT_Daily_Revenue_F= ExternalTaskSensor(
    pool = "sensor_pool",
    task_id=my_taskid,
    external_dag_id="D_INT_SCM",
    external_task_id="INT_Daily_Revenue_F",
    mode="reschedule",
    dag=D_DM_SCM,
    check_existence=True,
    timeout=60*60*1,
    retries=5,
    retry_delay=timedelta(minutes=3),
    execution_date_fn=sqlg_exec_date_fn
)


BRANCH_D_DM_SCMxD_INT_SCM__INT_Daily_Revenue_F.set_downstream(proxy_D_DM_SCMxD_INT_SCM__INT_Daily_Revenue_F)

BRANCH_D_DM_SCMxD_INT_SCM__INT_Daily_Revenue_F.set_downstream(D_DM_SCMxD_INT_SCM__INT_Daily_Revenue_F)

D_DM_SCMxD_INT_SCM__INT_Daily_Revenue_F.set_downstream(proxy_D_DM_SCMxD_INT_SCM__INT_Daily_Revenue_F)

def branch_D_DM_SCMxD_INT_SCM__INT_RFQ_Master(**context):
    mydag = context["dag"]
    dagbag = DagBag()
    upstream = dagbag.get_dag("D_INT_SCM")
			
    # print("branch::DEBUG:upstream.latest_execution_date:", upstream.latest_execution_date)
    # print("branch::DEBUG:mydag.execution_date:", context['execution_date'])
    up_sch_interval = std_interval.get(upstream.schedule_interval)
    my_sch_interval = std_interval.get(mydag.schedule_interval)

    if up_sch_interval is None or my_sch_interval is None:
        if (up_sch_interval is None and my_sch_interval is None) and (upstream.schedule_interval == mydag.schedule_interval):
            return ["proxy_D_DM_SCMxD_INT_SCM__INT_RFQ_Master","D_DM_SCMxD_INT_SCM__INT_RFQ_Master"]
    elif std_interval[upstream.schedule_interval] >= std_interval[mydag.schedule_interval]:
        if upstream.latest_execution_date == context["execution_date"]:
            return ["proxy_D_DM_SCMxD_INT_SCM__INT_RFQ_Master","D_DM_SCMxD_INT_SCM__INT_RFQ_Master"]
    return ["proxy_D_DM_SCMxD_INT_SCM__INT_RFQ_Master"]


my_taskid = "BRANCH_D_DM_SCMxD_INT_SCM__INT_RFQ_Master"
BRANCH_D_DM_SCMxD_INT_SCM__INT_RFQ_Master= BranchPythonOperator(
    task_id=my_taskid,
    python_callable=branch_D_DM_SCMxD_INT_SCM__INT_RFQ_Master,
    dag=D_DM_SCM,
    provide_context=True,
)


my_taskid = "proxy_D_DM_SCMxD_INT_SCM__INT_RFQ_Master"
proxy_D_DM_SCMxD_INT_SCM__INT_RFQ_Master= DummyOperator(
    task_id=my_taskid,
    trigger_rule="none_failed_or_skipped",
    dag=D_DM_SCM,
)


#   Cross dag sensor
			
my_taskid = "D_DM_SCMxD_INT_SCM__INT_RFQ_Master"
D_DM_SCMxD_INT_SCM__INT_RFQ_Master= ExternalTaskSensor(
    pool = "sensor_pool",
    task_id=my_taskid,
    external_dag_id="D_INT_SCM",
    external_task_id="INT_RFQ_Master",
    mode="reschedule",
    dag=D_DM_SCM,
    check_existence=True,
    timeout=60*60*1,
    retries=5,
    retry_delay=timedelta(minutes=3),
    execution_date_fn=sqlg_exec_date_fn
)


BRANCH_D_DM_SCMxD_INT_SCM__INT_RFQ_Master.set_downstream(proxy_D_DM_SCMxD_INT_SCM__INT_RFQ_Master)

BRANCH_D_DM_SCMxD_INT_SCM__INT_RFQ_Master.set_downstream(D_DM_SCMxD_INT_SCM__INT_RFQ_Master)

D_DM_SCMxD_INT_SCM__INT_RFQ_Master.set_downstream(proxy_D_DM_SCMxD_INT_SCM__INT_RFQ_Master)

def branch_D_DM_SCMxD_INT_SCM__INT_Inventory_A(**context):
    mydag = context["dag"]
    dagbag = DagBag()
    upstream = dagbag.get_dag("D_INT_SCM")
			
    # print("branch::DEBUG:upstream.latest_execution_date:", upstream.latest_execution_date)
    # print("branch::DEBUG:mydag.execution_date:", context['execution_date'])
    up_sch_interval = std_interval.get(upstream.schedule_interval)
    my_sch_interval = std_interval.get(mydag.schedule_interval)

    if up_sch_interval is None or my_sch_interval is None:
        if (up_sch_interval is None and my_sch_interval is None) and (upstream.schedule_interval == mydag.schedule_interval):
            return ["proxy_D_DM_SCMxD_INT_SCM__INT_Inventory_A","D_DM_SCMxD_INT_SCM__INT_Inventory_A"]
    elif std_interval[upstream.schedule_interval] >= std_interval[mydag.schedule_interval]:
        if upstream.latest_execution_date == context["execution_date"]:
            return ["proxy_D_DM_SCMxD_INT_SCM__INT_Inventory_A","D_DM_SCMxD_INT_SCM__INT_Inventory_A"]
    return ["proxy_D_DM_SCMxD_INT_SCM__INT_Inventory_A"]


my_taskid = "BRANCH_D_DM_SCMxD_INT_SCM__INT_Inventory_A"
BRANCH_D_DM_SCMxD_INT_SCM__INT_Inventory_A= BranchPythonOperator(
    task_id=my_taskid,
    python_callable=branch_D_DM_SCMxD_INT_SCM__INT_Inventory_A,
    dag=D_DM_SCM,
    provide_context=True,
)


my_taskid = "proxy_D_DM_SCMxD_INT_SCM__INT_Inventory_A"
proxy_D_DM_SCMxD_INT_SCM__INT_Inventory_A= DummyOperator(
    task_id=my_taskid,
    trigger_rule="none_failed_or_skipped",
    dag=D_DM_SCM,
)


#   Cross dag sensor
			
my_taskid = "D_DM_SCMxD_INT_SCM__INT_Inventory_A"
D_DM_SCMxD_INT_SCM__INT_Inventory_A= ExternalTaskSensor(
    pool = "sensor_pool",
    task_id=my_taskid,
    external_dag_id="D_INT_SCM",
    external_task_id="INT_Inventory_A",
    mode="reschedule",
    dag=D_DM_SCM,
    check_existence=True,
    timeout=60*60*1,
    retries=5,
    retry_delay=timedelta(minutes=3),
    execution_date_fn=sqlg_exec_date_fn
)


BRANCH_D_DM_SCMxD_INT_SCM__INT_Inventory_A.set_downstream(proxy_D_DM_SCMxD_INT_SCM__INT_Inventory_A)

BRANCH_D_DM_SCMxD_INT_SCM__INT_Inventory_A.set_downstream(D_DM_SCMxD_INT_SCM__INT_Inventory_A)

D_DM_SCMxD_INT_SCM__INT_Inventory_A.set_downstream(proxy_D_DM_SCMxD_INT_SCM__INT_Inventory_A)

def branch_D_DM_SCMxD_INT_SCM__INT_DOI_Actual(**context):
    mydag = context["dag"]
    dagbag = DagBag()
    upstream = dagbag.get_dag("D_INT_SCM")
			
    # print("branch::DEBUG:upstream.latest_execution_date:", upstream.latest_execution_date)
    # print("branch::DEBUG:mydag.execution_date:", context['execution_date'])
    up_sch_interval = std_interval.get(upstream.schedule_interval)
    my_sch_interval = std_interval.get(mydag.schedule_interval)

    if up_sch_interval is None or my_sch_interval is None:
        if (up_sch_interval is None and my_sch_interval is None) and (upstream.schedule_interval == mydag.schedule_interval):
            return ["proxy_D_DM_SCMxD_INT_SCM__INT_DOI_Actual","D_DM_SCMxD_INT_SCM__INT_DOI_Actual"]
    elif std_interval[upstream.schedule_interval] >= std_interval[mydag.schedule_interval]:
        if upstream.latest_execution_date == context["execution_date"]:
            return ["proxy_D_DM_SCMxD_INT_SCM__INT_DOI_Actual","D_DM_SCMxD_INT_SCM__INT_DOI_Actual"]
    return ["proxy_D_DM_SCMxD_INT_SCM__INT_DOI_Actual"]


my_taskid = "BRANCH_D_DM_SCMxD_INT_SCM__INT_DOI_Actual"
BRANCH_D_DM_SCMxD_INT_SCM__INT_DOI_Actual= BranchPythonOperator(
    task_id=my_taskid,
    python_callable=branch_D_DM_SCMxD_INT_SCM__INT_DOI_Actual,
    dag=D_DM_SCM,
    provide_context=True,
)


my_taskid = "proxy_D_DM_SCMxD_INT_SCM__INT_DOI_Actual"
proxy_D_DM_SCMxD_INT_SCM__INT_DOI_Actual= DummyOperator(
    task_id=my_taskid,
    trigger_rule="none_failed_or_skipped",
    dag=D_DM_SCM,
)


#   Cross dag sensor
			
my_taskid = "D_DM_SCMxD_INT_SCM__INT_DOI_Actual"
D_DM_SCMxD_INT_SCM__INT_DOI_Actual= ExternalTaskSensor(
    pool = "sensor_pool",
    task_id=my_taskid,
    external_dag_id="D_INT_SCM",
    external_task_id="INT_DOI_Actual",
    mode="reschedule",
    dag=D_DM_SCM,
    check_existence=True,
    timeout=60*60*1,
    retries=5,
    retry_delay=timedelta(minutes=3),
    execution_date_fn=sqlg_exec_date_fn
)


BRANCH_D_DM_SCMxD_INT_SCM__INT_DOI_Actual.set_downstream(proxy_D_DM_SCMxD_INT_SCM__INT_DOI_Actual)

BRANCH_D_DM_SCMxD_INT_SCM__INT_DOI_Actual.set_downstream(D_DM_SCMxD_INT_SCM__INT_DOI_Actual)

D_DM_SCMxD_INT_SCM__INT_DOI_Actual.set_downstream(proxy_D_DM_SCMxD_INT_SCM__INT_DOI_Actual)

def branch_D_INT_SCMxD_ODS_SCM__PNL_Revenue_Cost_A(**context):
    mydag = context["dag"]
    dagbag = DagBag()
    upstream = dagbag.get_dag("D_ODS_SCM")
			
    # print("branch::DEBUG:upstream.latest_execution_date:", upstream.latest_execution_date)
    # print("branch::DEBUG:mydag.execution_date:", context['execution_date'])
    up_sch_interval = std_interval.get(upstream.schedule_interval)
    my_sch_interval = std_interval.get(mydag.schedule_interval)

    if up_sch_interval is None or my_sch_interval is None:
        if (up_sch_interval is None and my_sch_interval is None) and (upstream.schedule_interval == mydag.schedule_interval):
            return ["proxy_D_INT_SCMxD_ODS_SCM__PNL_Revenue_Cost_A","D_INT_SCMxD_ODS_SCM__PNL_Revenue_Cost_A"]
    elif std_interval[upstream.schedule_interval] >= std_interval[mydag.schedule_interval]:
        if upstream.latest_execution_date == context["execution_date"]:
            return ["proxy_D_INT_SCMxD_ODS_SCM__PNL_Revenue_Cost_A","D_INT_SCMxD_ODS_SCM__PNL_Revenue_Cost_A"]
    return ["proxy_D_INT_SCMxD_ODS_SCM__PNL_Revenue_Cost_A"]


my_taskid = "BRANCH_D_INT_SCMxD_ODS_SCM__PNL_Revenue_Cost_A"
BRANCH_D_INT_SCMxD_ODS_SCM__PNL_Revenue_Cost_A= BranchPythonOperator(
    task_id=my_taskid,
    python_callable=branch_D_INT_SCMxD_ODS_SCM__PNL_Revenue_Cost_A,
    dag=D_INT_SCM,
    provide_context=True,
)


my_taskid = "proxy_D_INT_SCMxD_ODS_SCM__PNL_Revenue_Cost_A"
proxy_D_INT_SCMxD_ODS_SCM__PNL_Revenue_Cost_A= DummyOperator(
    task_id=my_taskid,
    trigger_rule="none_failed_or_skipped",
    dag=D_INT_SCM,
)


#   Cross dag sensor
			
my_taskid = "D_INT_SCMxD_ODS_SCM__PNL_Revenue_Cost_A"
D_INT_SCMxD_ODS_SCM__PNL_Revenue_Cost_A= ExternalTaskSensor(
    pool = "sensor_pool",
    task_id=my_taskid,
    external_dag_id="D_ODS_SCM",
    external_task_id="PNL_Revenue_Cost_A",
    mode="reschedule",
    dag=D_INT_SCM,
    check_existence=True,
    timeout=60*60*1,
    retries=5,
    retry_delay=timedelta(minutes=3),
    execution_date_fn=sqlg_exec_date_fn
)


BRANCH_D_INT_SCMxD_ODS_SCM__PNL_Revenue_Cost_A.set_downstream(proxy_D_INT_SCMxD_ODS_SCM__PNL_Revenue_Cost_A)

BRANCH_D_INT_SCMxD_ODS_SCM__PNL_Revenue_Cost_A.set_downstream(D_INT_SCMxD_ODS_SCM__PNL_Revenue_Cost_A)

D_INT_SCMxD_ODS_SCM__PNL_Revenue_Cost_A.set_downstream(proxy_D_INT_SCMxD_ODS_SCM__PNL_Revenue_Cost_A)

def branch_D_INT_SCMxD_ODS_SCM__NRE_Summary(**context):
    mydag = context["dag"]
    dagbag = DagBag()
    upstream = dagbag.get_dag("D_ODS_SCM")
			
    # print("branch::DEBUG:upstream.latest_execution_date:", upstream.latest_execution_date)
    # print("branch::DEBUG:mydag.execution_date:", context['execution_date'])
    up_sch_interval = std_interval.get(upstream.schedule_interval)
    my_sch_interval = std_interval.get(mydag.schedule_interval)

    if up_sch_interval is None or my_sch_interval is None:
        if (up_sch_interval is None and my_sch_interval is None) and (upstream.schedule_interval == mydag.schedule_interval):
            return ["proxy_D_INT_SCMxD_ODS_SCM__NRE_Summary","D_INT_SCMxD_ODS_SCM__NRE_Summary"]
    elif std_interval[upstream.schedule_interval] >= std_interval[mydag.schedule_interval]:
        if upstream.latest_execution_date == context["execution_date"]:
            return ["proxy_D_INT_SCMxD_ODS_SCM__NRE_Summary","D_INT_SCMxD_ODS_SCM__NRE_Summary"]
    return ["proxy_D_INT_SCMxD_ODS_SCM__NRE_Summary"]


my_taskid = "BRANCH_D_INT_SCMxD_ODS_SCM__NRE_Summary"
BRANCH_D_INT_SCMxD_ODS_SCM__NRE_Summary= BranchPythonOperator(
    task_id=my_taskid,
    python_callable=branch_D_INT_SCMxD_ODS_SCM__NRE_Summary,
    dag=D_INT_SCM,
    provide_context=True,
)


my_taskid = "proxy_D_INT_SCMxD_ODS_SCM__NRE_Summary"
proxy_D_INT_SCMxD_ODS_SCM__NRE_Summary= DummyOperator(
    task_id=my_taskid,
    trigger_rule="none_failed_or_skipped",
    dag=D_INT_SCM,
)


#   Cross dag sensor
			
my_taskid = "D_INT_SCMxD_ODS_SCM__NRE_Summary"
D_INT_SCMxD_ODS_SCM__NRE_Summary= ExternalTaskSensor(
    pool = "sensor_pool",
    task_id=my_taskid,
    external_dag_id="D_ODS_SCM",
    external_task_id="NRE_Summary",
    mode="reschedule",
    dag=D_INT_SCM,
    check_existence=True,
    timeout=60*60*1,
    retries=5,
    retry_delay=timedelta(minutes=3),
    execution_date_fn=sqlg_exec_date_fn
)


BRANCH_D_INT_SCMxD_ODS_SCM__NRE_Summary.set_downstream(proxy_D_INT_SCMxD_ODS_SCM__NRE_Summary)

BRANCH_D_INT_SCMxD_ODS_SCM__NRE_Summary.set_downstream(D_INT_SCMxD_ODS_SCM__NRE_Summary)

D_INT_SCMxD_ODS_SCM__NRE_Summary.set_downstream(proxy_D_INT_SCMxD_ODS_SCM__NRE_Summary)

def branch_D_INT_SCMxD_ODS_SCM__Daily_Revenue_F(**context):
    mydag = context["dag"]
    dagbag = DagBag()
    upstream = dagbag.get_dag("D_ODS_SCM")
			
    # print("branch::DEBUG:upstream.latest_execution_date:", upstream.latest_execution_date)
    # print("branch::DEBUG:mydag.execution_date:", context['execution_date'])
    up_sch_interval = std_interval.get(upstream.schedule_interval)
    my_sch_interval = std_interval.get(mydag.schedule_interval)

    if up_sch_interval is None or my_sch_interval is None:
        if (up_sch_interval is None and my_sch_interval is None) and (upstream.schedule_interval == mydag.schedule_interval):
            return ["proxy_D_INT_SCMxD_ODS_SCM__Daily_Revenue_F","D_INT_SCMxD_ODS_SCM__Daily_Revenue_F"]
    elif std_interval[upstream.schedule_interval] >= std_interval[mydag.schedule_interval]:
        if upstream.latest_execution_date == context["execution_date"]:
            return ["proxy_D_INT_SCMxD_ODS_SCM__Daily_Revenue_F","D_INT_SCMxD_ODS_SCM__Daily_Revenue_F"]
    return ["proxy_D_INT_SCMxD_ODS_SCM__Daily_Revenue_F"]


my_taskid = "BRANCH_D_INT_SCMxD_ODS_SCM__Daily_Revenue_F"
BRANCH_D_INT_SCMxD_ODS_SCM__Daily_Revenue_F= BranchPythonOperator(
    task_id=my_taskid,
    python_callable=branch_D_INT_SCMxD_ODS_SCM__Daily_Revenue_F,
    dag=D_INT_SCM,
    provide_context=True,
)


my_taskid = "proxy_D_INT_SCMxD_ODS_SCM__Daily_Revenue_F"
proxy_D_INT_SCMxD_ODS_SCM__Daily_Revenue_F= DummyOperator(
    task_id=my_taskid,
    trigger_rule="none_failed_or_skipped",
    dag=D_INT_SCM,
)


#   Cross dag sensor
			
my_taskid = "D_INT_SCMxD_ODS_SCM__Daily_Revenue_F"
D_INT_SCMxD_ODS_SCM__Daily_Revenue_F= ExternalTaskSensor(
    pool = "sensor_pool",
    task_id=my_taskid,
    external_dag_id="D_ODS_SCM",
    external_task_id="Daily_Revenue_F",
    mode="reschedule",
    dag=D_INT_SCM,
    check_existence=True,
    timeout=60*60*1,
    retries=5,
    retry_delay=timedelta(minutes=3),
    execution_date_fn=sqlg_exec_date_fn
)


BRANCH_D_INT_SCMxD_ODS_SCM__Daily_Revenue_F.set_downstream(proxy_D_INT_SCMxD_ODS_SCM__Daily_Revenue_F)

BRANCH_D_INT_SCMxD_ODS_SCM__Daily_Revenue_F.set_downstream(D_INT_SCMxD_ODS_SCM__Daily_Revenue_F)

D_INT_SCMxD_ODS_SCM__Daily_Revenue_F.set_downstream(proxy_D_INT_SCMxD_ODS_SCM__Daily_Revenue_F)

def branch_D_INT_SCMxD_ODS_SCM__RFQ_Master(**context):
    mydag = context["dag"]
    dagbag = DagBag()
    upstream = dagbag.get_dag("D_ODS_SCM")
			
    # print("branch::DEBUG:upstream.latest_execution_date:", upstream.latest_execution_date)
    # print("branch::DEBUG:mydag.execution_date:", context['execution_date'])
    up_sch_interval = std_interval.get(upstream.schedule_interval)
    my_sch_interval = std_interval.get(mydag.schedule_interval)

    if up_sch_interval is None or my_sch_interval is None:
        if (up_sch_interval is None and my_sch_interval is None) and (upstream.schedule_interval == mydag.schedule_interval):
            return ["proxy_D_INT_SCMxD_ODS_SCM__RFQ_Master","D_INT_SCMxD_ODS_SCM__RFQ_Master"]
    elif std_interval[upstream.schedule_interval] >= std_interval[mydag.schedule_interval]:
        if upstream.latest_execution_date == context["execution_date"]:
            return ["proxy_D_INT_SCMxD_ODS_SCM__RFQ_Master","D_INT_SCMxD_ODS_SCM__RFQ_Master"]
    return ["proxy_D_INT_SCMxD_ODS_SCM__RFQ_Master"]


my_taskid = "BRANCH_D_INT_SCMxD_ODS_SCM__RFQ_Master"
BRANCH_D_INT_SCMxD_ODS_SCM__RFQ_Master= BranchPythonOperator(
    task_id=my_taskid,
    python_callable=branch_D_INT_SCMxD_ODS_SCM__RFQ_Master,
    dag=D_INT_SCM,
    provide_context=True,
)


my_taskid = "proxy_D_INT_SCMxD_ODS_SCM__RFQ_Master"
proxy_D_INT_SCMxD_ODS_SCM__RFQ_Master= DummyOperator(
    task_id=my_taskid,
    trigger_rule="none_failed_or_skipped",
    dag=D_INT_SCM,
)


#   Cross dag sensor
			
my_taskid = "D_INT_SCMxD_ODS_SCM__RFQ_Master"
D_INT_SCMxD_ODS_SCM__RFQ_Master= ExternalTaskSensor(
    pool = "sensor_pool",
    task_id=my_taskid,
    external_dag_id="D_ODS_SCM",
    external_task_id="RFQ_Master",
    mode="reschedule",
    dag=D_INT_SCM,
    check_existence=True,
    timeout=60*60*1,
    retries=5,
    retry_delay=timedelta(minutes=3),
    execution_date_fn=sqlg_exec_date_fn
)


BRANCH_D_INT_SCMxD_ODS_SCM__RFQ_Master.set_downstream(proxy_D_INT_SCMxD_ODS_SCM__RFQ_Master)

BRANCH_D_INT_SCMxD_ODS_SCM__RFQ_Master.set_downstream(D_INT_SCMxD_ODS_SCM__RFQ_Master)

D_INT_SCMxD_ODS_SCM__RFQ_Master.set_downstream(proxy_D_INT_SCMxD_ODS_SCM__RFQ_Master)

def branch_D_INT_SCMxD_ODS_SCM__Inventory_A(**context):
    mydag = context["dag"]
    dagbag = DagBag()
    upstream = dagbag.get_dag("D_ODS_SCM")
			
    # print("branch::DEBUG:upstream.latest_execution_date:", upstream.latest_execution_date)
    # print("branch::DEBUG:mydag.execution_date:", context['execution_date'])
    up_sch_interval = std_interval.get(upstream.schedule_interval)
    my_sch_interval = std_interval.get(mydag.schedule_interval)

    if up_sch_interval is None or my_sch_interval is None:
        if (up_sch_interval is None and my_sch_interval is None) and (upstream.schedule_interval == mydag.schedule_interval):
            return ["proxy_D_INT_SCMxD_ODS_SCM__Inventory_A","D_INT_SCMxD_ODS_SCM__Inventory_A"]
    elif std_interval[upstream.schedule_interval] >= std_interval[mydag.schedule_interval]:
        if upstream.latest_execution_date == context["execution_date"]:
            return ["proxy_D_INT_SCMxD_ODS_SCM__Inventory_A","D_INT_SCMxD_ODS_SCM__Inventory_A"]
    return ["proxy_D_INT_SCMxD_ODS_SCM__Inventory_A"]


my_taskid = "BRANCH_D_INT_SCMxD_ODS_SCM__Inventory_A"
BRANCH_D_INT_SCMxD_ODS_SCM__Inventory_A= BranchPythonOperator(
    task_id=my_taskid,
    python_callable=branch_D_INT_SCMxD_ODS_SCM__Inventory_A,
    dag=D_INT_SCM,
    provide_context=True,
)


my_taskid = "proxy_D_INT_SCMxD_ODS_SCM__Inventory_A"
proxy_D_INT_SCMxD_ODS_SCM__Inventory_A= DummyOperator(
    task_id=my_taskid,
    trigger_rule="none_failed_or_skipped",
    dag=D_INT_SCM,
)


#   Cross dag sensor
			
my_taskid = "D_INT_SCMxD_ODS_SCM__Inventory_A"
D_INT_SCMxD_ODS_SCM__Inventory_A= ExternalTaskSensor(
    pool = "sensor_pool",
    task_id=my_taskid,
    external_dag_id="D_ODS_SCM",
    external_task_id="Inventory_A",
    mode="reschedule",
    dag=D_INT_SCM,
    check_existence=True,
    timeout=60*60*1,
    retries=5,
    retry_delay=timedelta(minutes=3),
    execution_date_fn=sqlg_exec_date_fn
)


BRANCH_D_INT_SCMxD_ODS_SCM__Inventory_A.set_downstream(proxy_D_INT_SCMxD_ODS_SCM__Inventory_A)

BRANCH_D_INT_SCMxD_ODS_SCM__Inventory_A.set_downstream(D_INT_SCMxD_ODS_SCM__Inventory_A)

D_INT_SCMxD_ODS_SCM__Inventory_A.set_downstream(proxy_D_INT_SCMxD_ODS_SCM__Inventory_A)

def branch_D_INT_SCMxD_ODS_SCM__DOI_Actual(**context):
    mydag = context["dag"]
    dagbag = DagBag()
    upstream = dagbag.get_dag("D_ODS_SCM")
			
    # print("branch::DEBUG:upstream.latest_execution_date:", upstream.latest_execution_date)
    # print("branch::DEBUG:mydag.execution_date:", context['execution_date'])
    up_sch_interval = std_interval.get(upstream.schedule_interval)
    my_sch_interval = std_interval.get(mydag.schedule_interval)

    if up_sch_interval is None or my_sch_interval is None:
        if (up_sch_interval is None and my_sch_interval is None) and (upstream.schedule_interval == mydag.schedule_interval):
            return ["proxy_D_INT_SCMxD_ODS_SCM__DOI_Actual","D_INT_SCMxD_ODS_SCM__DOI_Actual"]
    elif std_interval[upstream.schedule_interval] >= std_interval[mydag.schedule_interval]:
        if upstream.latest_execution_date == context["execution_date"]:
            return ["proxy_D_INT_SCMxD_ODS_SCM__DOI_Actual","D_INT_SCMxD_ODS_SCM__DOI_Actual"]
    return ["proxy_D_INT_SCMxD_ODS_SCM__DOI_Actual"]


my_taskid = "BRANCH_D_INT_SCMxD_ODS_SCM__DOI_Actual"
BRANCH_D_INT_SCMxD_ODS_SCM__DOI_Actual= BranchPythonOperator(
    task_id=my_taskid,
    python_callable=branch_D_INT_SCMxD_ODS_SCM__DOI_Actual,
    dag=D_INT_SCM,
    provide_context=True,
)


my_taskid = "proxy_D_INT_SCMxD_ODS_SCM__DOI_Actual"
proxy_D_INT_SCMxD_ODS_SCM__DOI_Actual= DummyOperator(
    task_id=my_taskid,
    trigger_rule="none_failed_or_skipped",
    dag=D_INT_SCM,
)


#   Cross dag sensor
			
my_taskid = "D_INT_SCMxD_ODS_SCM__DOI_Actual"
D_INT_SCMxD_ODS_SCM__DOI_Actual= ExternalTaskSensor(
    pool = "sensor_pool",
    task_id=my_taskid,
    external_dag_id="D_ODS_SCM",
    external_task_id="DOI_Actual",
    mode="reschedule",
    dag=D_INT_SCM,
    check_existence=True,
    timeout=60*60*1,
    retries=5,
    retry_delay=timedelta(minutes=3),
    execution_date_fn=sqlg_exec_date_fn
)


BRANCH_D_INT_SCMxD_ODS_SCM__DOI_Actual.set_downstream(proxy_D_INT_SCMxD_ODS_SCM__DOI_Actual)

BRANCH_D_INT_SCMxD_ODS_SCM__DOI_Actual.set_downstream(D_INT_SCMxD_ODS_SCM__DOI_Actual)

D_INT_SCMxD_ODS_SCM__DOI_Actual.set_downstream(proxy_D_INT_SCMxD_ODS_SCM__DOI_Actual)
	
# 	XSLT:loop: JOB_FLOW_NAME-and-PRE_JOB: External: END}}


# XSLT:loop: JOB_FLOW_NAME: START{

# 	XSLT:loop: Rows-by-JOB_FLOW_NAME: JOB_NAME: START{{
# 	 	FLOW: D_ODS_SCM.PNL_Revenue_Cost_A
proxy_D_ODS_SCMxD_STG_INIT__SYS_STS_STG.set_downstream(PNL_Revenue_Cost_A)
proxy_D_ODS_SCMxD_STG_INIT__SYS_STS_STG.set_downstream(NRE_Summary)
proxy_D_ODS_SCMxD_STG_INIT__SYS_STS_STG.set_downstream(Daily_Revenue_F)
proxy_D_ODS_SCMxD_STG_INIT__SYS_STS_STG.set_downstream(RFQ_Master)
proxy_D_ODS_SCMxD_STG_INIT__SYS_STS_STG.set_downstream(Inventory_A)
proxy_D_ODS_SCMxD_STG_INIT__SYS_STS_STG.set_downstream(DOI_Actual)

# 	XSLT:loop: Rows-by-JOB_FLOW_NAME: JOB_NAME: START{{
# 	 	FLOW: D_DM_SCM.DM_PNL_Revenue_Cost_A
proxy_D_DM_SCMxD_INT_SCM__INT_PNL_Revenue_Cost_A.set_downstream(DM_PNL_Revenue_Cost_A)
proxy_D_DM_SCMxD_INT_SCM__INT_NRE_Summary.set_downstream(DM_NRE_Summary)
proxy_D_DM_SCMxD_INT_SCM__INT_Daily_Revenue_F.set_downstream(DM_Daily_Revenue_F)
proxy_D_DM_SCMxD_INT_SCM__INT_RFQ_Master.set_downstream(DM_RFQ_Master)
proxy_D_DM_SCMxD_INT_SCM__INT_Inventory_A.set_downstream(DM_Inventory_A)
proxy_D_DM_SCMxD_INT_SCM__INT_DOI_Actual.set_downstream(DM_DOI_Actual)

# 	XSLT:loop: Rows-by-JOB_FLOW_NAME: JOB_NAME: START{{
# 	 	FLOW: D_INT_SCM.INT_PNL_Revenue_Cost_A
proxy_D_INT_SCMxD_ODS_SCM__PNL_Revenue_Cost_A.set_downstream(INT_PNL_Revenue_Cost_A)
proxy_D_INT_SCMxD_ODS_SCM__NRE_Summary.set_downstream(INT_NRE_Summary)
proxy_D_INT_SCMxD_ODS_SCM__Daily_Revenue_F.set_downstream(INT_Daily_Revenue_F)
proxy_D_INT_SCMxD_ODS_SCM__RFQ_Master.set_downstream(INT_RFQ_Master)
proxy_D_INT_SCMxD_ODS_SCM__Inventory_A.set_downstream(INT_Inventory_A)
proxy_D_INT_SCMxD_ODS_SCM__DOI_Actual.set_downstream(INT_DOI_Actual)

